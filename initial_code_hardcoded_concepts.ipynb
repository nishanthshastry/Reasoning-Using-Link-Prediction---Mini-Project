{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# Don't execute this cell always\n",
    "\n",
    "#see notebook to see where this was born\n",
    "\n",
    "# a graph is a 2d array of characters\n",
    "\n",
    "\n",
    "'''\n",
    "# 2D array \n",
    "rows, cols = (10, 10) \n",
    "arr = [[\" \" for i in range(cols)] for j in range(rows)] \n",
    "print(arr) \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't execute this cell always\n",
    "\n",
    "\n",
    "# To be done only once (the first time you'll create the graph)\n",
    "\n",
    "# You cannot see this data in the file, it'll say it is not UTF encoded. But you can write and extract it from the code\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "my_list = [[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n",
    "\n",
    "with open('graph.txt', 'wb') as f:\n",
    "    pickle.dump(my_list, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# Don't execute this cell always\n",
    "\n",
    "\n",
    "# import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', 'bs', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# Don't execute this cell always\n",
    "\n",
    "\n",
    "# Testing cell\n",
    "\n",
    "# import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "b[1][1] = 'bs'\n",
    "\n",
    "with open('graph.txt', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "    \n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    st = pickle.load(fp)\n",
    "    \n",
    "print(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_row = 0\n",
    "data_input_col = 0\n",
    "\n",
    "\n",
    "ques_input_row = 9\n",
    "ques_input_col = 9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter data: Bangalore is the Sillicon Valley of India.\n",
      "[['Bangalore is the Sillicon Valley of India.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', 'bs', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "data = input(\"Enter data: \")\n",
    "\n",
    "\n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "b[data_input_row][data_input_col] = data\n",
    "\n",
    "data_input_col += 1\n",
    "\n",
    "if(data_input_col >= 10):\n",
    "    data_input_col = 0\n",
    "    data_input_row += 1\n",
    "\n",
    "with open('graph.txt', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "    \n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    st = pickle.load(fp)\n",
    "    \n",
    "print(st)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial list is:\n",
      "[['Bangalore is the Sillicon Valley of India.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', 'bs', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n",
      "New assigned list is\n",
      "[['Bangalore is the Sillicon Valley of India.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', 'bs', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# Now we have both the question and the answer\n",
    "\n",
    "# let's preprocess them\n",
    "\n",
    "\n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Input_list = pickle.load(fp)\n",
    "\n",
    "# Python program to copy a nested list \n",
    "  \n",
    "# List initialization \n",
    "copy = []  \n",
    "  \n",
    "# Using iteration to assign values \n",
    "for x in range(len(Input_list)): \n",
    "    temp = [] \n",
    "    for elem in Input_list[x]: \n",
    "        temp.append(elem) \n",
    "    copy.append(temp) \n",
    "  \n",
    "\n",
    "\n",
    "print(\"Initial list is:\") \n",
    "print(Input_list) \n",
    "print(\"New assigned list is\") \n",
    "print(copy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Bangalore is the Sillicon Valley of India', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', 'bs', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '], [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']]\n"
     ]
    }
   ],
   "source": [
    "# Import string for a list of punctuations\n",
    "import string\n",
    "\n",
    "for i in range(len(copy)):\n",
    "    for j in range(len(copy[i])):\n",
    "        temp_str = \"\"\n",
    "        for c in copy[i][j]:\n",
    "            if(c not in string.punctuation):\n",
    "                temp_str += c\n",
    "        copy[i][j] = temp_str\n",
    "        \n",
    "                \n",
    "print(copy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Bangalore Sillicon Valley India ', '', '', '', '', '', '', '', '', ''], ['', 'bs ', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "# Import Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "# Import the stop word list\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(copy)):\n",
    "    for j in range(len(copy[i])):\n",
    "        l1 = copy[i][j].split()\n",
    "        s1 = \"\"\n",
    "        for k in l1:\n",
    "            if k not in stopwords.words('english'):\n",
    "                s1 = s1 + k + \" \"\n",
    "        copy[i][j] = s1\n",
    "                    \n",
    "print(copy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bangalor sillicon valley india ', '', '', '', '', '', '', '', '', ''], ['', 'bs ', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', ''], ['', '', '', '', '', '', '', '', '', '']]\n"
     ]
    }
   ],
   "source": [
    "# Import Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "# Import stemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Instantiate stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(len(copy)):\n",
    "    for j in range(len(copy[i])):\n",
    "        l1 = copy[i][j].split()\n",
    "        s1 = \"\"\n",
    "        for k in l1:\n",
    "            s1 = s1 + stemmer.stem(k) + \" \"\n",
    "        copy[i][j] = s1\n",
    "                    \n",
    "print(copy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bangalor': 1, 'sillicon': 1, 'valley': 1, 'india': 1, 'bs': 1}\n"
     ]
    }
   ],
   "source": [
    "unique_word_dict = dict()\n",
    "\n",
    "for i in range(len(copy)):\n",
    "    for j in range(len(copy[i])):\n",
    "        l1 = copy[i][j].split()\n",
    "        for k in l1: \n",
    "            if(k not in unique_word_dict.keys()):\n",
    "                unique_word_dict[k] = 0\n",
    "            unique_word_dict[k] += 1\n",
    "\n",
    "print(unique_word_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your question: Which city is the Sillicon Valley of India ?\n",
      "Which city is the Sillicon Valley of India ?\n"
     ]
    }
   ],
   "source": [
    "question = input(\"Enter your question: \")\n",
    "\n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "b[ques_input_row][ques_input_col] = question\n",
    "\n",
    "ques_input_col -= 1\n",
    "\n",
    "if(ques_input_col < 0):\n",
    "    ques_input_col = 9\n",
    "    ques_input_row -= 1\n",
    "\n",
    "with open('graph.txt', 'wb') as f:\n",
    "    pickle.dump(b, f)\n",
    "    \n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    st = pickle.load(fp)\n",
    "    \n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which', 'city', 'is', 'the', 'Sillicon', 'Valley', 'of', 'India', '?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_list = question.split()\n",
    "question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bangalor': -0.6931471805599453, 'sillicon': -0.6931471805599453, 'valley': -0.6931471805599453, 'india': -0.6931471805599453, 'bs': -0.6931471805599453}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "inverse_document_freq = dict()\n",
    "\n",
    "for k in unique_word_dict.keys():\n",
    "    if k not in inverse_document_freq:\n",
    "        inverse_document_freq[k] = 0\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for i in range(len(copy)):\n",
    "        for j in range(len(copy[i])):\n",
    "            if(len(copy[i][j])):\n",
    "                if k in copy[i][j].split():\n",
    "                    num += 1\n",
    "                den += 1\n",
    "            \n",
    "    inverse_document_freq[k] = math.log(num / den)\n",
    "    \n",
    "print(inverse_document_freq)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'bangalor': -0.17328679513998632,\n",
       "   'sillicon': -0.17328679513998632,\n",
       "   'valley': -0.17328679513998632,\n",
       "   'india': -0.17328679513998632},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {},\n",
       "  {}],\n",
       " [{}, {'bs': -0.6931471805599453}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}],\n",
       " [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, cols = (10, 10) \n",
    "tfidf_list = [[dict() for i in range(cols)] for j in range(rows)] \n",
    "\n",
    " \n",
    "\n",
    "for j in range(len(copy)):\n",
    "    for k in range(len(copy[j])):\n",
    "        l1 = []\n",
    "        l1 = copy[j][k].split()\n",
    "        term_frequency = dict()\n",
    "        \n",
    "        for h in l1:\n",
    "            if (h not in term_frequency.keys()):\n",
    "                term_frequency[h] = 0.0\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "            for a in l1:\n",
    "                if(a == h):\n",
    "                    numerator += 1\n",
    "                denominator += 1\n",
    "                \n",
    "            term_frequency[h] = numerator / denominator\n",
    "            tfidf_list[j][k] = term_frequency\n",
    "            \n",
    "for i in range(len(tfidf_list)):\n",
    "    for j in range(len(tfidf_list[i])):\n",
    "        for k in tfidf_list[i][j].keys():\n",
    "            tfidf_list[i][j][k] *= inverse_document_freq[k] \n",
    "            \n",
    "\n",
    "# Every element in the 2d array is a document, this tfidf_list has a dictionary for every document.\n",
    "# This dictionary has the tfidf value for each word in the document\n",
    "tfidf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore is the Sillicon Valley of India.\n"
     ]
    }
   ],
   "source": [
    "max = -9999 #Beware tfidf value can be negative as well\n",
    "t_row = 0\n",
    "t_col = 0\n",
    "\n",
    "for a in question_list:\n",
    "    for i in range(len(tfidf_list)):\n",
    "        for j in range(len(tfidf_list[i])):\n",
    "            if a in tfidf_list[i][j].keys():\n",
    "                if (tfidf_list[i][j][a] > max):\n",
    "                    max = tfidf_list[i][j][a]\n",
    "                    t_row = i\n",
    "                    t_col = j\n",
    "                    \n",
    "# This returns the entire document, we can further build it \n",
    "# to return only the sentence in which the word appears.\n",
    "                    \n",
    "with open(\"graph.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)\n",
    "    \n",
    "#print(b)    \n",
    "                    \n",
    "print(b[t_row][t_col])\n",
    "\n",
    "X = b[t_row][t_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cosine Similarity application'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine Similarity application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bangalore is the Sillicon Valley of India.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which city is the Sillicon Valley of India ?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = word_tokenize(X)  \n",
    "Y_list = word_tokenize(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# sw contains the list of stopwords \n",
    "sw = stopwords.words('english')  \n",
    "l1 =[]\n",
    "l2 =[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words from the string \n",
    "X_set = {w for w in X_list if not w in sw}  \n",
    "Y_set = {w for w in Y_list if not w in sw} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a set containing keywords of both strings  \n",
    "rvector = X_set.union(Y_set)  \n",
    "for w in rvector: \n",
    "    if w in X_set: l1.append(1) # create a vector \n",
    "    else: l1.append(0) \n",
    "    if w in Y_set: l2.append(1) \n",
    "    else: l2.append(0) \n",
    "c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity:  0.5477225575051661\n"
     ]
    }
   ],
   "source": [
    "# cosine formula  \n",
    "for i in range(len(rvector)): \n",
    "        c+= l1[i]*l2[i] \n",
    "cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
    "print(\"similarity: \", cosine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
